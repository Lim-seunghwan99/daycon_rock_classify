{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd40994e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.ipc_collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f756248a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linux\n"
     ]
    }
   ],
   "source": [
    "import platform\n",
    "print(platform.system()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae52c6e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Version: 12.4\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# PyTorch의 CUDA 버전 확인\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA Version: {torch.version.cuda}\")\n",
    "else:\n",
    "    print(\"CUDA는 사용할 수 없습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7eb51f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 파일 개수 (서브폴더 포함): 33452\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "folder_path = './open/train/Weathered_Rock/'\n",
    "total_file_count = 0\n",
    "\n",
    "for root, dirs, files in os.walk(folder_path):\n",
    "    total_file_count += len(files)\n",
    "\n",
    "print(f\"전체 파일 개수 (서브폴더 포함): {total_file_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7b4c0b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'open/train/Mud_Sandstone' 안의 하위 폴더 목록:\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "folder_path = Path('./open/train/Mud_Sandstone')\n",
    "\n",
    "subdirs = [d for d in folder_path.iterdir() if d.is_dir()]\n",
    "\n",
    "print(f\"'{folder_path}' 안의 하위 폴더 목록:\")\n",
    "for subdir in subdirs:\n",
    "    print(subdir.name)  # 폴더 이름만 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ee5e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hiera_small_abswin_256.sbb2_e200_in12k', 'hiera_small_abswin_256.sbb2_e200_in12k_ft_in1k', 'hiera_small_abswin_256.sbb2_pd_e200_in12k', 'hiera_small_abswin_256.sbb2_pd_e200_in12k_ft_in1k', 'swin_base_patch4_window7_224.ms_in1k']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/metaai2/miniconda3/envs/env312_cuda124_torch260/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import timm\n",
    "import torch\n",
    "\n",
    "# 별도로 해당 모델에 맞는 입력 전처리 방법을 확인하고 적용해야 합니다.\n",
    "# 위 코드의 resolve_data_config와 create_transform 부분이 바로 이 역할을 합니다. \n",
    "# timm을 사용할 때는 이 전처리 부분을 놓치지 않는 것이 매우 중요합니다.\n",
    "available_swin_models = timm.list_models('*swin*', pretrained=True)\n",
    "print(available_swin_models[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b51e826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 특정 Swin Transformer 모델 불러오기 (ImageNet 사전 훈련 가중치 포함)\n",
    "model_name = 'swin_large_patch4_window12_384.ms_in22k_ft_in1k' # 원하는 Swin 모델 이름 선택\n",
    "transfer_model_swin = timm.create_model(model_name, pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed75f3b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "print(next(transfer_model_swin.parameters()).device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "940c4c15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SwinTransformer(\n",
       "  (patch_embed): PatchEmbed(\n",
       "    (proj): Conv2d(3, 192, kernel_size=(4, 4), stride=(4, 4))\n",
       "    (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (layers): Sequential(\n",
       "    (0): SwinTransformerStage(\n",
       "      (downsample): Identity()\n",
       "      (blocks): Sequential(\n",
       "        (0): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (1): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path1): DropPath(drop_prob=0.004)\n",
       "          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path2): DropPath(drop_prob=0.004)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): SwinTransformerStage(\n",
       "      (downsample): PatchMerging(\n",
       "        (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (reduction): Linear(in_features=768, out_features=384, bias=False)\n",
       "      )\n",
       "      (blocks): Sequential(\n",
       "        (0): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path1): DropPath(drop_prob=0.009)\n",
       "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path2): DropPath(drop_prob=0.009)\n",
       "        )\n",
       "        (1): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path1): DropPath(drop_prob=0.013)\n",
       "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path2): DropPath(drop_prob=0.013)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): SwinTransformerStage(\n",
       "      (downsample): PatchMerging(\n",
       "        (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (reduction): Linear(in_features=1536, out_features=768, bias=False)\n",
       "      )\n",
       "      (blocks): Sequential(\n",
       "        (0): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path1): DropPath(drop_prob=0.017)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path2): DropPath(drop_prob=0.017)\n",
       "        )\n",
       "        (1): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path1): DropPath(drop_prob=0.022)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path2): DropPath(drop_prob=0.022)\n",
       "        )\n",
       "        (2): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path1): DropPath(drop_prob=0.026)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path2): DropPath(drop_prob=0.026)\n",
       "        )\n",
       "        (3): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path1): DropPath(drop_prob=0.030)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path2): DropPath(drop_prob=0.030)\n",
       "        )\n",
       "        (4): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path1): DropPath(drop_prob=0.035)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path2): DropPath(drop_prob=0.035)\n",
       "        )\n",
       "        (5): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path1): DropPath(drop_prob=0.039)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path2): DropPath(drop_prob=0.039)\n",
       "        )\n",
       "        (6): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path1): DropPath(drop_prob=0.043)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path2): DropPath(drop_prob=0.043)\n",
       "        )\n",
       "        (7): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path1): DropPath(drop_prob=0.048)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path2): DropPath(drop_prob=0.048)\n",
       "        )\n",
       "        (8): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path1): DropPath(drop_prob=0.052)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path2): DropPath(drop_prob=0.052)\n",
       "        )\n",
       "        (9): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path1): DropPath(drop_prob=0.057)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path2): DropPath(drop_prob=0.057)\n",
       "        )\n",
       "        (10): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path1): DropPath(drop_prob=0.061)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path2): DropPath(drop_prob=0.061)\n",
       "        )\n",
       "        (11): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path1): DropPath(drop_prob=0.065)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path2): DropPath(drop_prob=0.065)\n",
       "        )\n",
       "        (12): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path1): DropPath(drop_prob=0.070)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path2): DropPath(drop_prob=0.070)\n",
       "        )\n",
       "        (13): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path1): DropPath(drop_prob=0.074)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path2): DropPath(drop_prob=0.074)\n",
       "        )\n",
       "        (14): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path1): DropPath(drop_prob=0.078)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path2): DropPath(drop_prob=0.078)\n",
       "        )\n",
       "        (15): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path1): DropPath(drop_prob=0.083)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path2): DropPath(drop_prob=0.083)\n",
       "        )\n",
       "        (16): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path1): DropPath(drop_prob=0.087)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path2): DropPath(drop_prob=0.087)\n",
       "        )\n",
       "        (17): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path1): DropPath(drop_prob=0.091)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path2): DropPath(drop_prob=0.091)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): SwinTransformerStage(\n",
       "      (downsample): PatchMerging(\n",
       "        (norm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
       "        (reduction): Linear(in_features=3072, out_features=1536, bias=False)\n",
       "      )\n",
       "      (blocks): Sequential(\n",
       "        (0): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=1536, out_features=4608, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path1): DropPath(drop_prob=0.096)\n",
       "          (norm2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path2): DropPath(drop_prob=0.096)\n",
       "        )\n",
       "        (1): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=1536, out_features=4608, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path1): DropPath(drop_prob=0.100)\n",
       "          (norm2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path2): DropPath(drop_prob=0.100)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "  (head): ClassifierHead(\n",
       "    (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Identity())\n",
       "    (drop): Dropout(p=0.0, inplace=False)\n",
       "    (fc): Linear(in_features=1536, out_features=1000, bias=True)\n",
       "    (flatten): Identity()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transfer_model_swin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3bf91b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClassifierHead(\n",
      "  (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Identity())\n",
      "  (drop): Dropout(p=0.0, inplace=False)\n",
      "  (fc): Linear(in_features=1536, out_features=1000, bias=True)\n",
      "  (flatten): Identity()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(transfer_model_swin.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba3a7b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 분류기(Classifier Head) 수정 (내 데이터셋 클래스 수에 맞게)\n",
    "num_classes = 7 # 암석 종류 7가지\n",
    "in_features = transfer_model_swin.head.fc.in_features # transfer_model_swin.head로 transfer_model_swin.head 인지 .fc를 붙이는 지 차이가 있다.\n",
    "transfer_model_swin.head.fc = torch.nn.Linear(in_features, num_classes)  # fc 레이어 교체"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44fe3657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClassifierHead(\n",
      "  (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Identity())\n",
      "  (drop): Dropout(p=0.0, inplace=False)\n",
      "  (fc): Linear(in_features=1536, out_features=7, bias=True)\n",
      "  (flatten): Identity()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(transfer_model_swin.head) # 바뀐 head 구조 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "761f2cdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_size': (3, 384, 384),\n",
       " 'interpolation': 'bicubic',\n",
       " 'mean': (0.485, 0.456, 0.406),\n",
       " 'std': (0.229, 0.224, 0.225),\n",
       " 'crop_pct': 1.0,\n",
       " 'crop_mode': 'center'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# timm 모델은 torchvision의 weights.transforms() 와 같은 자동 전처리 기능을 제공하지 않음\n",
    "# 따라서, 모델에 맞는 전처리 방법을 직접 설정해야 함\n",
    "# 모델에 맞는 입력 설정값 가져오기 (이미지 크기, 정규화 평균/표준편차 등)\n",
    "config = timm.data.resolve_data_config({}, model=transfer_model_swin)\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae89f13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습용 Transform\n",
    "train_transform = timm.data.transforms_factory.create_transform(**config, is_training=True)\n",
    "# 검증/테스트용 Transform\n",
    "val_transform = timm.data.transforms_factory.create_transform(**config, is_training=False) # 변수 이름 명확화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed1e2451",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Compose(\n",
       "    RandomResizedCropAndInterpolation(size=(384, 384), scale=(0.08, 1.0), ratio=(0.75, 1.3333), interpolation=bicubic)\n",
       "    RandomHorizontalFlip(p=0.5)\n",
       "    ColorJitter(brightness=(0.6, 1.4), contrast=(0.6, 1.4), saturation=(0.6, 1.4), hue=None)\n",
       "    MaybeToTensor()\n",
       "    Normalize(mean=tensor([0.4850, 0.4560, 0.4060]), std=tensor([0.2290, 0.2240, 0.2250]))\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_transform\n",
    "# 아래에서 수정하기 전에 기본값 참고를 위해 생성성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0997ad58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compose(\n",
      "    Resize(size=384, interpolation=bicubic, max_size=None, antialias=True)\n",
      "    CenterCrop(size=(384, 384))\n",
      "    MaybeToTensor()\n",
      "    Normalize(mean=tensor([0.4850, 0.4560, 0.4060]), std=tensor([0.2290, 0.2240, 0.2250]))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(val_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "26c59ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "img_size = 384\n",
    "imagenet_mean = [0.485, 0.456, 0.406]\n",
    "imagenet_std = [0.229, 0.224, 0.225]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cf12966f",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_rr_crop_scale = (0.5, 1.0)  # 스케일 최소값 증가 (예: 0.5)\n",
    "new_cj_brightness = 0.2         # 밝기 변화 강도 감소 (예: +/- 20%)\n",
    "new_cj_contrast = 0.2           # 대비 변화 강도 감소\n",
    "new_cj_saturation = 0.2         # 채도 변화 강도 감소\n",
    "rotation_degrees = 15\n",
    "\n",
    "added_rotation_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(size=img_size, scale=new_rr_crop_scale, ratio=(0.75, 1.3333), interpolation=transforms.InterpolationMode.BICUBIC),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=15, interpolation=transforms.InterpolationMode.BILINEAR, fill=0), \n",
    "    transforms.ColorJitter(brightness=new_cj_brightness, contrast=new_cj_contrast, saturation=new_cj_saturation),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=imagenet_mean, std=imagenet_std)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "039d22f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path \n",
    "# 데이터 경로 \n",
    "\n",
    "train_data_path = Path(\"./open/train\") # 실제 학습 데이터 경로\n",
    "val_data_path = Path(\"./open/val\")     # 실제 검증 데이터 경로 (이전 단계에서 생성)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "088d55a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "학습 데이터셋 크기: 342015개 이미지\n",
      "검증 데이터셋 크기: 38005개 이미지\n"
     ]
    }
   ],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "# 학습 데이터셋: train_transform 적용\n",
    "train_dataset = ImageFolder(root=train_data_path, transform=added_rotation_transform)\n",
    "\n",
    "# 검증 데이터셋: val_transform 적용\n",
    "val_dataset = ImageFolder(root=val_data_path, transform=val_transform)\n",
    "\n",
    "print(f\"\\n학습 데이터셋 크기: {len(train_dataset)}개 이미지\")\n",
    "print(f\"검증 데이터셋 크기: {len(val_dataset)}개 이미지\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6bbf3469",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Andesite': 0,\n",
       " 'Basalt': 1,\n",
       " 'Etc': 2,\n",
       " 'Gneiss': 3,\n",
       " 'Granite': 4,\n",
       " 'Mud_Sandstone': 5,\n",
       " 'Weathered_Rock': 6}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_idx = train_dataset.class_to_idx\n",
    "class_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1f69a4df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Andesite',\n",
       " 1: 'Basalt',\n",
       " 2: 'Etc',\n",
       " 3: 'Gneiss',\n",
       " 4: 'Granite',\n",
       " 5: 'Mud_Sandstone',\n",
       " 6: 'Weathered_Rock'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names = {class_idx[key]: key for key in class_idx.keys()}\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7fc5f8b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 로더 생성 완료: Train 배치 21376, Val 배치 2376\n",
      "클래스: ['Andesite', 'Basalt', 'Etc', 'Gneiss', 'Granite', 'Mud_Sandstone', 'Weathered_Rock']\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "BATCH_SIZE = 16 # 배치 사이즈 설정 (GPU 메모리 상황에 맞게 조정)\n",
    "NUM_WORKERS = 4 # 데이터 로딩을 위한 프로세스 수 (CPU 코어 수에 맞게 조정)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "print(f\"데이터 로더 생성 완료: Train 배치 {len(train_loader)}, Val 배치 {len(val_loader)}\")\n",
    "print(f\"클래스: {train_dataset.classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "030e298d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사용할 장치: cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SwinTransformer(\n",
       "  (patch_embed): PatchEmbed(\n",
       "    (proj): Conv2d(3, 192, kernel_size=(4, 4), stride=(4, 4))\n",
       "    (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (layers): Sequential(\n",
       "    (0): SwinTransformerStage(\n",
       "      (downsample): Identity()\n",
       "      (blocks): Sequential(\n",
       "        (0): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (1): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path1): DropPath(drop_prob=0.004)\n",
       "          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path2): DropPath(drop_prob=0.004)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): SwinTransformerStage(\n",
       "      (downsample): PatchMerging(\n",
       "        (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (reduction): Linear(in_features=768, out_features=384, bias=False)\n",
       "      )\n",
       "      (blocks): Sequential(\n",
       "        (0): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path1): DropPath(drop_prob=0.009)\n",
       "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path2): DropPath(drop_prob=0.009)\n",
       "        )\n",
       "        (1): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path1): DropPath(drop_prob=0.013)\n",
       "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path2): DropPath(drop_prob=0.013)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): SwinTransformerStage(\n",
       "      (downsample): PatchMerging(\n",
       "        (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (reduction): Linear(in_features=1536, out_features=768, bias=False)\n",
       "      )\n",
       "      (blocks): Sequential(\n",
       "        (0): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path1): DropPath(drop_prob=0.017)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path2): DropPath(drop_prob=0.017)\n",
       "        )\n",
       "        (1): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path1): DropPath(drop_prob=0.022)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path2): DropPath(drop_prob=0.022)\n",
       "        )\n",
       "        (2): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path1): DropPath(drop_prob=0.026)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path2): DropPath(drop_prob=0.026)\n",
       "        )\n",
       "        (3): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path1): DropPath(drop_prob=0.030)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path2): DropPath(drop_prob=0.030)\n",
       "        )\n",
       "        (4): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path1): DropPath(drop_prob=0.035)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path2): DropPath(drop_prob=0.035)\n",
       "        )\n",
       "        (5): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path1): DropPath(drop_prob=0.039)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path2): DropPath(drop_prob=0.039)\n",
       "        )\n",
       "        (6): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path1): DropPath(drop_prob=0.043)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path2): DropPath(drop_prob=0.043)\n",
       "        )\n",
       "        (7): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path1): DropPath(drop_prob=0.048)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path2): DropPath(drop_prob=0.048)\n",
       "        )\n",
       "        (8): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path1): DropPath(drop_prob=0.052)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path2): DropPath(drop_prob=0.052)\n",
       "        )\n",
       "        (9): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path1): DropPath(drop_prob=0.057)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path2): DropPath(drop_prob=0.057)\n",
       "        )\n",
       "        (10): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path1): DropPath(drop_prob=0.061)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path2): DropPath(drop_prob=0.061)\n",
       "        )\n",
       "        (11): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path1): DropPath(drop_prob=0.065)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path2): DropPath(drop_prob=0.065)\n",
       "        )\n",
       "        (12): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path1): DropPath(drop_prob=0.070)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path2): DropPath(drop_prob=0.070)\n",
       "        )\n",
       "        (13): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path1): DropPath(drop_prob=0.074)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path2): DropPath(drop_prob=0.074)\n",
       "        )\n",
       "        (14): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path1): DropPath(drop_prob=0.078)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path2): DropPath(drop_prob=0.078)\n",
       "        )\n",
       "        (15): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path1): DropPath(drop_prob=0.083)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path2): DropPath(drop_prob=0.083)\n",
       "        )\n",
       "        (16): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path1): DropPath(drop_prob=0.087)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path2): DropPath(drop_prob=0.087)\n",
       "        )\n",
       "        (17): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path1): DropPath(drop_prob=0.091)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path2): DropPath(drop_prob=0.091)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): SwinTransformerStage(\n",
       "      (downsample): PatchMerging(\n",
       "        (norm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
       "        (reduction): Linear(in_features=3072, out_features=1536, bias=False)\n",
       "      )\n",
       "      (blocks): Sequential(\n",
       "        (0): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=1536, out_features=4608, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path1): DropPath(drop_prob=0.096)\n",
       "          (norm2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path2): DropPath(drop_prob=0.096)\n",
       "        )\n",
       "        (1): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=1536, out_features=4608, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path1): DropPath(drop_prob=0.100)\n",
       "          (norm2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path2): DropPath(drop_prob=0.100)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "  (head): ClassifierHead(\n",
       "    (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Identity())\n",
       "    (drop): Dropout(p=0.0, inplace=False)\n",
       "    (fc): Linear(in_features=1536, out_features=7, bias=True)\n",
       "    (flatten): Identity()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델을 GPU로 이동\n",
    "DEVICE_STR = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"사용할 장치: {DEVICE_STR}\")\n",
    "transfer_model_swin.to(DEVICE_STR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cd462127",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=None, gamma=2., reduction='mean'):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        # alpha: 클래스별 가중치 (Tensor or list or float). None이면 균등 가중치.\n",
    "        # gamma: Focusing 파라미터.\n",
    "        # reduction: 'mean', 'sum', 'none'\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        # inputs: 모델 출력 로짓 (N, C)\n",
    "        # targets: 실제 레이블 (N,)\n",
    "        ce_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
    "        pt = torch.exp(-ce_loss) # p_t = exp(-CrossEntropy)\n",
    "        focal_loss = ((1 - pt) ** self.gamma) * ce_loss\n",
    "\n",
    "        if self.alpha is not None:\n",
    "            # alpha를 target 클래스에 맞게 적용\n",
    "            if isinstance(self.alpha, (float, int)):\n",
    "                 alpha = torch.tensor([self.alpha] * inputs.shape[1], device=inputs.device)\n",
    "            elif isinstance(self.alpha, list):\n",
    "                 alpha = torch.tensor(self.alpha, device=inputs.device, dtype=torch.float32)\n",
    "            elif torch.is_tensor(self.alpha):\n",
    "                 alpha = self.alpha.to(device=inputs.device, dtype=torch.float32)\n",
    "            else:\n",
    "                 raise TypeError(\"alpha must be float, list or torch.Tensor\")\n",
    "\n",
    "            if alpha.shape[0] != inputs.shape[1]:\n",
    "                 raise ValueError(f\"alpha size {alpha.shape[0]} does not match C {inputs.shape[1]}\")\n",
    "\n",
    "            alpha_t = alpha.gather(0, targets) # 각 샘플의 정답 클래스에 해당하는 alpha 값 선택\n",
    "            focal_loss = alpha_t * focal_loss\n",
    "\n",
    "        # reduction 적용\n",
    "        if self.reduction == 'mean':\n",
    "            return focal_loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return focal_loss.sum()\n",
    "        else: # 'none'\n",
    "            return focal_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ab148f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "# --- 손실 함수 및 옵티마이저 정의 ---\n",
    "EPOCHS = 20 # 테스트용 에폭 수\n",
    "NUM_CLASSES = num_classes # 암석 종류 7가지\n",
    "WARMUP_EPOCHS = 5 # Warmup 에폭 수\n",
    "LEARNING_RATE = 1e-5\n",
    "focal_loss_gamma = 2.0 # Focal Loss 감마 값 (튜닝 대상 3)\n",
    "focal_loss_alpha = None\n",
    "\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "criterion = FocalLoss(alpha=focal_loss_alpha, gamma=focal_loss_gamma)\n",
    "optimizer = optim.AdamW(transfer_model_swin.parameters(), lr=LEARNING_RATE, weight_decay=0.01)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=EPOCHS - WARMUP_EPOCHS, eta_min=LEARNING_RATE * 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d645e494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1, 2, 3, 4, 5, 6}\n"
     ]
    }
   ],
   "source": [
    "print(set(train_dataset.targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1c5591c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Optimizer # Optimizer 타입 힌트용\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import torchmetrics # torchmetrics 임포트\n",
    "import time # 시간 측정을 위해 추가\n",
    "\n",
    "def train_and_validate_best_f1(model: nn.Module,\n",
    "                               train_loader: DataLoader,\n",
    "                               val_loader: DataLoader,\n",
    "                               optimizer: Optimizer,\n",
    "                               criterion: nn.Module, # Loss function\n",
    "                               epochs: int,\n",
    "                               device: torch.device,\n",
    "                               num_classes: int,\n",
    "                               save_path: str,\n",
    "                               gradient_clipping: float = None, # 기본값 None 설정\n",
    "                               lr_scheduler = None, # LR 스케줄러 추가 (선택적)\n",
    "                               warmup_epochs: int = 0, # Warmup 에폭 추가 (선택적)\n",
    "                               base_lr: float = 1e-5 # Warmup을 위한 기본 LR (선택적)\n",
    "                              ):\n",
    "    \n",
    "    history = {'train_losses': [], 'val_losses': [], 'val_macro_f1_scores': []}\n",
    "    # 최고 F1 점수 추적 (0.0으로 초기화)\n",
    "    max_val_f1 = 0.0\n",
    "    best_epoch = -1 # 최고 성능을 기록한 에폭 저장\n",
    "\n",
    "    # Macro F1 계산 메트릭 초기화 (F1Score 사용)\n",
    "    f1_metric = torchmetrics.F1Score(task='multiclass', num_classes=num_classes, average='macro').to(device)\n",
    "\n",
    "    patience = 5 # 조기 종료를 위한 patience 설정\n",
    "    epochs_no_improve = 0 # 성능 개선이 없는 에폭 수 카운트\n",
    "\n",
    "    print(f\"학습 시작: 총 {epochs} 에폭, Device: {device}\")\n",
    "    print(f\"최적 모델 저장 경로: {save_path}\")\n",
    "    print(f\"평가 기준: Validation Macro F1 Score\")\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        epoch_start_time = time.time()\n",
    "        current_lr = optimizer.param_groups[0]['lr'] # 현재 LR 확인 (스케줄러 적용 전)\n",
    "\n",
    "        # --- Warmup 및 LR 스케줄링 (선택적) ---\n",
    "        if epoch < warmup_epochs:\n",
    "            # Linear Warmup\n",
    "            warmup_factor = (epoch + 1) / warmup_epochs\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = base_lr * warmup_factor\n",
    "            current_lr = optimizer.param_groups[0]['lr'] # 업데이트된 LR\n",
    "        elif lr_scheduler is not None:\n",
    "             # Warmup 이후 스케줄러 적용\n",
    "             if epoch == warmup_epochs:\n",
    "                 # Warmup 직후에는 base_lr로 설정 (CosineAnnealing 등 일부 스케줄러에 필요)\n",
    "                 for param_group in optimizer.param_groups:\n",
    "                     param_group['lr'] = base_lr\n",
    "                 # 첫 스케줄러 스텝은 base_lr 기준으로 시작해야 할 수 있음 (스케줄러 종류에 따라 다름)\n",
    "                 # 일부 스케줄러는 optimizer 생성 시점의 LR을 사용하므로, base_lr로 optimizer 재생성 또는 LR 재설정이 필요할 수 있음\n",
    "                 # 여기서는 첫 스텝 전에 LR을 강제로 맞추고 step() 호출\n",
    "                 lr_scheduler.step() # 첫 스텝 호출\n",
    "             else:\n",
    "                 lr_scheduler.step() # 이후 에폭에서는 계속 step()\n",
    "             current_lr = optimizer.param_groups[0]['lr'] # 업데이트된 LR\n",
    "\n",
    "\n",
    "        # --- 학습 단계 ---\n",
    "        model.train()\n",
    "        running_train_loss = 0.0\n",
    "        train_pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs} [Train] LR: {current_lr:.1e}\", leave=False)\n",
    "\n",
    "        for images, labels in train_pbar:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            # --- Gradient Clipping ---\n",
    "            if gradient_clipping is not None:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), gradient_clipping)\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            running_train_loss += loss.item()\n",
    "            train_pbar.set_postfix(loss=f\"{loss.item():.4f}\") # 손실 포맷팅\n",
    "\n",
    "        epoch_train_loss = running_train_loss / len(train_loader)\n",
    "        history['train_losses'].append(epoch_train_loss)\n",
    "\n",
    "        # --- 검증 단계 ---\n",
    "        model.eval()\n",
    "        running_val_loss = 0.0\n",
    "        f1_metric.reset() # 각 에폭 시작 전 F1 메트릭 리셋\n",
    "        val_pbar = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{epochs} [Val] \", leave=False)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_pbar:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels) # 검증 손실도 계산\n",
    "                running_val_loss += loss.item()\n",
    "\n",
    "                # F1 메트릭 업데이트 (정확도 대신)\n",
    "                f1_metric.update(outputs, labels)\n",
    "                val_pbar.set_postfix(loss=f\"{loss.item():.4f}\") # 손실 포맷팅\n",
    "\n",
    "        epoch_val_loss = running_val_loss / len(val_loader)\n",
    "        history['val_losses'].append(epoch_val_loss)\n",
    "\n",
    "        # Macro F1 점수 계산 (정확도 대신)\n",
    "        epoch_val_f1 = f1_metric.compute().item() # .item()으로 스칼라 값 추출\n",
    "        history['val_macro_f1_scores'].append(epoch_val_f1) # history 업데이트\n",
    "\n",
    "        epoch_end_time = time.time()\n",
    "        epoch_duration = epoch_end_time - epoch_start_time\n",
    "\n",
    "        # 에폭 결과 출력 (Accuracy -> Macro F1)\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}] ({epoch_duration:.2f}s) - \"\n",
    "              f\"Train Loss: {epoch_train_loss:.4f}, \"\n",
    "              f\"Val Loss: {epoch_val_loss:.4f}, \"\n",
    "              f\"Val Macro F1: {epoch_val_f1:.4f}\") # 출력 업데이트\n",
    "\n",
    "        # 최고 모델 저장 로직 업데이트 (min_val_loss -> max_val_f1)\n",
    "        if epoch_val_f1 > max_val_f1:\n",
    "            max_val_f1 = epoch_val_f1\n",
    "            best_epoch = epoch # 최고 성능 에폭 기록\n",
    "            epochs_no_improve = 0 # 개선되었으므로 카운터 리셋\n",
    "            try:\n",
    "                 torch.save(model.state_dict(), save_path)\n",
    "                 print(f\"  => Best model saved to {save_path} (Epoch {epoch+1}, Val Macro F1: {max_val_f1:.4f})\")\n",
    "            except Exception as e:\n",
    "                 print(f\"  Error saving model: {e}\")\n",
    "        else:\n",
    "            epochs_no_improve += 1 # 성능 개선 없음, 카운터 증가\n",
    "            print(f\"  Val Macro F1 did not improve from {max_val_f1:.4f} ({epochs_no_improve}/{patience})\")\n",
    "\n",
    "        # 조기 종료 조건 확인\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(f\"Early stopping triggered at epoch {epoch+1} after {patience} epochs without improvement.\")\n",
    "            break # 학습 루프 종료\n",
    "\n",
    "    print(f\"\\n학습 완료. Best Epoch: {best_epoch+1}, Best Validation Macro F1: {max_val_f1:.4f}\")\n",
    "    print(f\"최적 모델 저장 경로: {save_path}\")\n",
    "\n",
    "    # 만약 조기 종료 등으로 인해 best_epoch 이후 모델 상태가 저장되었다면,\n",
    "    # 가장 좋았던 시점의 모델을 다시 로드하는 것이 안전할 수 있습니다.\n",
    "    # (선택적) 마지막에 최고 성능 모델 로드\n",
    "    if best_epoch != -1:\n",
    "        try:\n",
    "            model.load_state_dict(torch.load(save_path, map_location=device))\n",
    "            print(f\"Loaded best model state from epoch {best_epoch+1}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading best model state: {e}\")\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7487eeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model: nn.Module,\n",
    "# train_loader: DataLoader,\n",
    "# val_loader: DataLoader,\n",
    "# optimizer: Optimizer,\n",
    "# criterion: nn.Module, # Loss function\n",
    "# epochs: int,\n",
    "# device: torch.device,\n",
    "# num_classes: int,\n",
    "# save_path: str,\n",
    "# gradient_clipping: float = None, # 기본값 None 설정\n",
    "# lr_scheduler = None, # LR 스케줄러 추가 (선택적)\n",
    "# warmup_epochs: int = 0, # Warmup 에폭 추가 (선택적)\n",
    "# base_lr: float = 1e-5 # Warmup을 위한 기본 LR (선택적)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "123964a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 시작: 총 20 에폭, Device: cuda\n",
      "최적 모델 저장 경로: best_swin_large_model_test2.pth\n",
      "평가 기준: Validation Macro F1 Score\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 23.64 GiB of which 25.00 MiB is free. Process 324636 has 21.97 GiB memory in use. Including non-PyTorch memory, this process has 1.62 GiB memory in use. Of the allocated memory 1.12 GiB is allocated by PyTorch, and 71.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOutOfMemoryError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m SAVE_MODEL_PATH = \u001b[33m'\u001b[39m\u001b[33mbest_swin_large_model_test2.pth\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m history_f1 = \u001b[43mtrain_and_validate_best_f1\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtransfer_model_swin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mDEVICE_STR\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mNUM_CLASSES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43msave_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mSAVE_MODEL_PATH\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgradient_clipping\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlr_scheduler\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# 설정한 스케줄러 전달\u001b[39;49;00m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwarmup_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mWARMUP_EPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m      \u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbase_lr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mLEARNING_RATE\u001b[49m\u001b[43m             \u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m--- 테스트 학습 종료 ---\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     20\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m최적 모델 저장 경로 (테스트 중 저장되었다면): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mSAVE_MODEL_PATH\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 71\u001b[39m, in \u001b[36mtrain_and_validate_best_f1\u001b[39m\u001b[34m(model, train_loader, val_loader, optimizer, criterion, epochs, device, num_classes, save_path, gradient_clipping, lr_scheduler, warmup_epochs, base_lr)\u001b[39m\n\u001b[32m     68\u001b[39m train_pbar = tqdm(train_loader, desc=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m [Train] LR: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcurrent_lr\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.1e\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m, leave=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     70\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m images, labels \u001b[38;5;129;01min\u001b[39;00m train_pbar:\n\u001b[32m---> \u001b[39m\u001b[32m71\u001b[39m     images, labels = \u001b[43mimages\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m, labels.to(device)\n\u001b[32m     73\u001b[39m     optimizer.zero_grad()\n\u001b[32m     74\u001b[39m     outputs = model(images)\n",
      "\u001b[31mOutOfMemoryError\u001b[39m: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 23.64 GiB of which 25.00 MiB is free. Process 324636 has 21.97 GiB memory in use. Including non-PyTorch memory, this process has 1.62 GiB memory in use. Of the allocated memory 1.12 GiB is allocated by PyTorch, and 71.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "SAVE_MODEL_PATH = 'best_swin_large_model_test2.pth'\n",
    "\n",
    "history_f1 = train_and_validate_best_f1(\n",
    "    model=transfer_model_swin,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    epochs=EPOCHS,\n",
    "    device=DEVICE_STR,\n",
    "    num_classes=NUM_CLASSES,\n",
    "    save_path=SAVE_MODEL_PATH,\n",
    "    gradient_clipping=1.0, \n",
    "    lr_scheduler=scheduler, # 설정한 스케줄러 전달\n",
    "    warmup_epochs=WARMUP_EPOCHS,      \n",
    "    base_lr=LEARNING_RATE             \n",
    ")\n",
    "\n",
    "print(\"\\n--- 테스트 학습 종료 ---\")\n",
    "print(f\"최적 모델 저장 경로 (테스트 중 저장되었다면): {SAVE_MODEL_PATH}\")\n",
    "\n",
    "# --- (선택 사항) 학습 결과 활용 ---\n",
    "if history_f1['accuracies'] and not all(torch.isnan(torch.tensor(history_f1['accuracies']))): # NaN 값 제외하고 확인\n",
    "    print(f\"마지막 에폭 검증 정확도: {history_f1['accuracies'][-1]:.4f}\")\n",
    "    valid_val_losses = [loss for loss in history_f1['val_losses'] if not torch.isnan(torch.tensor(loss))]\n",
    "    if valid_val_losses:\n",
    "        best_epoch_idx = history_f1['val_losses'].index(min(valid_val_losses))\n",
    "        print(f\"최고 검증 성능 에폭: {best_epoch_idx + 1}\")\n",
    "        print(f\"  - 검증 손실: {history_f1['val_losses'][best_epoch_idx]:.4f}\")\n",
    "        print(f\"  - 검증 정확도: {history_f1['accuracies'][best_epoch_idx]:.4f}\")\n",
    "    else:\n",
    "        print(\"유효한 검증 손실 기록이 없습니다.\")\n",
    "else:\n",
    "    print(\"학습/검증 결과가 없습니다 (처리된 배치 없음).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2d60ba33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resolved timm data config: {'input_size': (3, 384, 384), 'interpolation': 'bicubic', 'mean': (0.485, 0.456, 0.406), 'std': (0.229, 0.224, 0.225), 'crop_pct': 1.0, 'crop_mode': 'center'}\n",
      "Created test transform using timm:\n",
      "Compose(\n",
      "    Resize(size=384, interpolation=bicubic, max_size=None, antialias=True)\n",
      "    CenterCrop(size=(384, 384))\n",
      "    MaybeToTensor()\n",
      "    Normalize(mean=tensor([0.4850, 0.4560, 0.4060]), std=tensor([0.2290, 0.2240, 0.2250]))\n",
      ")\n",
      "Loaded test CSV from ./open/test.csv with 95006 samples.\n",
      "Test DataLoader created. Number of batches: 5938\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "# from torchvision import transforms # timm의 transform을 사용하므로 주석 처리 가능\n",
    "from PIL import Image\n",
    "import os\n",
    "import timm # timm 라이브러리 import\n",
    "\n",
    "# --- 기본 설정 ---\n",
    "TEST_CSV_PATH = './open/test.csv'\n",
    "IMAGE_BASE_DIR = './open' # test.csv의 img_path가 상대 경로일 경우 기준점\n",
    "\n",
    "# --- 모델 및 설정 (이 부분은 이미 로드되어 있다고 가정) ---\n",
    "# 예시: transfer_model_swin = timm.create_model(...)\n",
    "# transfer_model_swin = None # Placeholder - 실제 모델 객체로 대체 필요\n",
    "\n",
    "# # 모델 로드 예시 (실제 코드에 맞게 수정)\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# transfer_model_swin = timm.create_model('swin_base_patch4_window12_384', pretrained=True) # 예시 모델 이름\n",
    "# # 필요하다면 체크포인트 로드\n",
    "# # transfer_model_swin.load_state_dict(torch.load('path/to/your/model_weights.pth'))\n",
    "# transfer_model_swin = transfer_model_swin.to(device)\n",
    "# transfer_model_swin.eval() # 평가 모드 설정\n",
    "\n",
    "# --- timm을 사용한 변환 설정 ---\n",
    "# !!! 중요 !!!: 아래 transfer_model_swin 변수가 실제 로드된 모델 객체를 참조해야 합니다.\n",
    "if 'transfer_model_swin' not in locals() or transfer_model_swin is None:\n",
    "     raise NameError(\"`transfer_model_swin` is not defined. Please load your model first.\")\n",
    "\n",
    "# 1. 모델로부터 데이터 설정 확인\n",
    "config = timm.data.resolve_data_config({}, model=transfer_model_swin)\n",
    "print(\"Resolved timm data config:\", config)\n",
    "\n",
    "# 2. 설정 기반으로 테스트용 변환 생성 (is_training=False)\n",
    "test_transform = timm.data.create_transform(**config, is_training=False)\n",
    "print(\"Created test transform using timm:\")\n",
    "print(test_transform)\n",
    "\n",
    "\n",
    "# --- 테스트 데이터용 Dataset 클래스 정의 (이전과 거의 동일) ---\n",
    "class RockTestDataset(Dataset):\n",
    "    def __init__(self, csv_path, img_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_path (string): test.csv 파일 경로.\n",
    "            img_dir (string): 이미지 파일들이 있는 기본 디렉토리 경로.\n",
    "            transform (callable, optional): 샘플에 적용될 변환.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.test_frame = pd.read_csv(csv_path)\n",
    "        except FileNotFoundError:\n",
    "             raise FileNotFoundError(f\"Test CSV file not found at: {csv_path}\")\n",
    "\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        print(f\"Loaded test CSV from {csv_path} with {len(self.test_frame)} samples.\")\n",
    "\n",
    "        if 'img_path' not in self.test_frame.columns:\n",
    "            raise ValueError(\"CSV file must contain an 'img_path' column.\")\n",
    "        # ID 컬럼은 submission 생성 시 필요하므로 확인\n",
    "        if 'ID' not in self.test_frame.columns:\n",
    "            raise ValueError(\"CSV file must contain an 'ID' column for submission.\")\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.test_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_relative_path = self.test_frame.iloc[idx]['img_path']\n",
    "\n",
    "        # 이미지 전체 경로 구성 (환경에 맞게 조정 필요)\n",
    "        if img_relative_path.startswith('./'):\n",
    "             # './open/test_imgs/...' 같은 형태 처리\n",
    "             img_full_path = os.path.join(os.path.dirname(TEST_CSV_PATH), img_relative_path.lstrip('./'))\n",
    "        elif os.path.isabs(img_relative_path):\n",
    "             # 절대 경로인 경우\n",
    "             img_full_path = img_relative_path\n",
    "        else:\n",
    "             # img_dir 기준 상대 경로인 경우\n",
    "             img_full_path = os.path.join(self.img_dir, img_relative_path)\n",
    "\n",
    "        try:\n",
    "            # 이미지 로드 (RGB 변환 필수)\n",
    "            image = Image.open(img_full_path).convert('RGB')\n",
    "        except FileNotFoundError:\n",
    "            print(f\"ERROR: Image not found at {img_full_path} (Index: {idx})\")\n",
    "            # 오류 발생 시 처리 (예: 빈 텐서 반환 후 예측 시 처리 또는 예외 발생)\n",
    "            raise FileNotFoundError(f\"Image file not found: {img_full_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"ERROR: Could not load image {img_full_path} (Index: {idx}): {e}\")\n",
    "            raise RuntimeError(f\"Failed to load image: {img_full_path}\") from e\n",
    "\n",
    "        # 변환 적용\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # 예측 함수가 input만 필요하면 image만 반환\n",
    "        # 만약 파일명 등 추가 정보가 필요하면 튜플로 반환 (예: return image, self.test_frame.iloc[idx]['ID'])\n",
    "        # 이전 `predict` 함수는 (inputs, _) 형태를 가정했으므로, 아무 값이나 추가로 반환해도 됨\n",
    "        img_id = self.test_frame.iloc[idx]['ID'] # ID를 함께 반환하는 예시\n",
    "        return image, img_id\n",
    "\n",
    "\n",
    "# --- Test Dataset 인스턴스 생성 ---\n",
    "try:\n",
    "    test_dataset = RockTestDataset(csv_path=TEST_CSV_PATH,\n",
    "                                   img_dir=IMAGE_BASE_DIR,\n",
    "                                   transform=test_transform)\n",
    "except (FileNotFoundError, ValueError, NameError) as e:\n",
    "    print(f\"Error creating Test Dataset: {e}\")\n",
    "    # 적절한 오류 처리 (예: 프로그램 종료)\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred during Test Dataset creation: {e}\")\n",
    "    exit()\n",
    "\n",
    "\n",
    "# --- Test DataLoader 생성 ---\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False, # 테스트 시에는 순서를 섞지 않습니다!\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True # GPU 사용 시 권장\n",
    ")\n",
    "\n",
    "print(f\"Test DataLoader created. Number of batches: {len(test_loader)}\")\n",
    "\n",
    "# 이제 이 test_loader를 create_submission_file 함수의 loader 인자로 사용할 수 있습니다.\n",
    "# 예시:\n",
    "# if __name__ == \"__main__\":\n",
    "#     ... (모델 로드, device 설정 - 이미 되어 있다고 가정) ...\n",
    "#\n",
    "#     # 필수 변수 확인 (model 객체가 로드되었는지)\n",
    "#     if 'transfer_model_swin' not in locals() or transfer_model_swin is None:\n",
    "#         print(\"Error: 'transfer_model_swin' is not defined or loaded.\")\n",
    "#     elif test_loader is None:\n",
    "#          print(\"Error: 'test_loader' could not be created.\")\n",
    "#     else:\n",
    "#         # 이전 답변의 함수 사용\n",
    "#         create_submission_file(\n",
    "#             model=transfer_model_swin, # 실제 로드된 모델 객체\n",
    "#             loader=test_loader,\n",
    "#             device=device, # device 설정 필요\n",
    "#             test_csv_path=TEST_CSV_PATH,\n",
    "#             submission_csv_path='./submission.csv', # 저장 경로 설정\n",
    "#             class_names={...} # 클래스 이름 딕셔너리 설정\n",
    "#         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "63db8e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SwinTransformer(\n",
       "  (patch_embed): PatchEmbed(\n",
       "    (proj): Conv2d(3, 192, kernel_size=(4, 4), stride=(4, 4))\n",
       "    (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (layers): Sequential(\n",
       "    (0): SwinTransformerStage(\n",
       "      (downsample): Identity()\n",
       "      (blocks): Sequential(\n",
       "        (0): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (1): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path1): DropPath(drop_prob=0.004)\n",
       "          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path2): DropPath(drop_prob=0.004)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): SwinTransformerStage(\n",
       "      (downsample): PatchMerging(\n",
       "        (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (reduction): Linear(in_features=768, out_features=384, bias=False)\n",
       "      )\n",
       "      (blocks): Sequential(\n",
       "        (0): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path1): DropPath(drop_prob=0.009)\n",
       "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path2): DropPath(drop_prob=0.009)\n",
       "        )\n",
       "        (1): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path1): DropPath(drop_prob=0.013)\n",
       "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path2): DropPath(drop_prob=0.013)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): SwinTransformerStage(\n",
       "      (downsample): PatchMerging(\n",
       "        (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (reduction): Linear(in_features=1536, out_features=768, bias=False)\n",
       "      )\n",
       "      (blocks): Sequential(\n",
       "        (0): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path1): DropPath(drop_prob=0.017)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path2): DropPath(drop_prob=0.017)\n",
       "        )\n",
       "        (1): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path1): DropPath(drop_prob=0.022)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path2): DropPath(drop_prob=0.022)\n",
       "        )\n",
       "        (2): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path1): DropPath(drop_prob=0.026)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path2): DropPath(drop_prob=0.026)\n",
       "        )\n",
       "        (3): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path1): DropPath(drop_prob=0.030)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path2): DropPath(drop_prob=0.030)\n",
       "        )\n",
       "        (4): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path1): DropPath(drop_prob=0.035)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path2): DropPath(drop_prob=0.035)\n",
       "        )\n",
       "        (5): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path1): DropPath(drop_prob=0.039)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path2): DropPath(drop_prob=0.039)\n",
       "        )\n",
       "        (6): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path1): DropPath(drop_prob=0.043)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path2): DropPath(drop_prob=0.043)\n",
       "        )\n",
       "        (7): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path1): DropPath(drop_prob=0.048)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path2): DropPath(drop_prob=0.048)\n",
       "        )\n",
       "        (8): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path1): DropPath(drop_prob=0.052)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path2): DropPath(drop_prob=0.052)\n",
       "        )\n",
       "        (9): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path1): DropPath(drop_prob=0.057)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path2): DropPath(drop_prob=0.057)\n",
       "        )\n",
       "        (10): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path1): DropPath(drop_prob=0.061)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path2): DropPath(drop_prob=0.061)\n",
       "        )\n",
       "        (11): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path1): DropPath(drop_prob=0.065)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path2): DropPath(drop_prob=0.065)\n",
       "        )\n",
       "        (12): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path1): DropPath(drop_prob=0.070)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path2): DropPath(drop_prob=0.070)\n",
       "        )\n",
       "        (13): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path1): DropPath(drop_prob=0.074)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path2): DropPath(drop_prob=0.074)\n",
       "        )\n",
       "        (14): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path1): DropPath(drop_prob=0.078)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path2): DropPath(drop_prob=0.078)\n",
       "        )\n",
       "        (15): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path1): DropPath(drop_prob=0.083)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path2): DropPath(drop_prob=0.083)\n",
       "        )\n",
       "        (16): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path1): DropPath(drop_prob=0.087)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path2): DropPath(drop_prob=0.087)\n",
       "        )\n",
       "        (17): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path1): DropPath(drop_prob=0.091)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path2): DropPath(drop_prob=0.091)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): SwinTransformerStage(\n",
       "      (downsample): PatchMerging(\n",
       "        (norm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
       "        (reduction): Linear(in_features=3072, out_features=1536, bias=False)\n",
       "      )\n",
       "      (blocks): Sequential(\n",
       "        (0): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=1536, out_features=4608, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path1): DropPath(drop_prob=0.096)\n",
       "          (norm2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path2): DropPath(drop_prob=0.096)\n",
       "        )\n",
       "        (1): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=1536, out_features=4608, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path1): DropPath(drop_prob=0.100)\n",
       "          (norm2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path2): DropPath(drop_prob=0.100)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "  (head): ClassifierHead(\n",
       "    (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Identity())\n",
       "    (drop): Dropout(p=0.0, inplace=False)\n",
       "    (fc): Linear(in_features=1536, out_features=7, bias=True)\n",
       "    (flatten): Identity()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_NAME = 'swin_large_patch4_window12_384.ms_in22k_ft_in1k'\n",
    "SAVED_MODEL_PATH = 'best_swin_large_model_test2.pth'\n",
    "NUM_CLASSES  = 7 # 암석 종류 7가지\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 동일한 모델 아키텍처 생성\n",
    "transfer_model_swin = timm.create_model(MODEL_NAME, pretrained=False, num_classes=NUM_CLASSES)\n",
    "saved_state_dict = torch.load(SAVED_MODEL_PATH, map_location=torch.device('cpu'))\n",
    "\n",
    "# 모델에 가중치 적용\n",
    "transfer_model_swin.load_state_dict(saved_state_dict)\n",
    "\n",
    "# gpu로 이동\n",
    "print(device)\n",
    "transfer_model_swin = transfer_model_swin.to(device)\n",
    "# 모델을 평가모드로 설정\n",
    "transfer_model_swin.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fda4ac3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5938/5938 [14:50<00:00,  6.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 결과가 test_with_predictions2.csv에 저장되었습니다.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[5,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 0,\n",
       " 5,\n",
       " 0,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 6,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " ...]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# DataFrame에서 이미지 경로를 읽고, CustomDataset으로 데이터셋 생성\n",
    "test = pd.read_csv('./open/test.csv')\n",
    "\n",
    "# 예측 및 시각화 함수\n",
    "def predict_and_visualize(model, loader, device):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, filenames in tqdm(iter(loader)):\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            pred = torch.argmax(outputs, dim=1)\n",
    "            \n",
    "            preds += pred.detach().cpu().numpy().tolist()\n",
    "\n",
    "    return preds  # 예측 결과를 반환\n",
    "\n",
    "# inference 함수와 predict_and_visualize를 결합한 함수\n",
    "def inference_and_visualize(model, loader, device):\n",
    "    preds = predict_and_visualize(model, loader, device)\n",
    "    \n",
    "    # 예측 결과를 원본 DataFrame에 추가\n",
    "    test['predictions'] = preds\n",
    "    \n",
    "    # 예측 결과를 새로운 CSV 파일로 저장\n",
    "    test.to_csv('./test_with_predictions2.csv', index=False)\n",
    "    print(\"예측 결과가 test_with_predictions2.csv에 저장되었습니다.\")\n",
    "    \n",
    "    return preds\n",
    "\n",
    "device = \"cuda\"\n",
    "inference_and_visualize(transfer_model_swin, test_loader, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "de18428c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>img_path</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_00000</td>\n",
       "      <td>./test/TEST_00000.jpg</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_00001</td>\n",
       "      <td>./test/TEST_00001.jpg</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_00002</td>\n",
       "      <td>./test/TEST_00002.jpg</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_00003</td>\n",
       "      <td>./test/TEST_00003.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_00004</td>\n",
       "      <td>./test/TEST_00004.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID               img_path  predictions\n",
       "0  TEST_00000  ./test/TEST_00000.jpg            5\n",
       "1  TEST_00001  ./test/TEST_00001.jpg            5\n",
       "2  TEST_00002  ./test/TEST_00002.jpg            5\n",
       "3  TEST_00003  ./test/TEST_00003.jpg            4\n",
       "4  TEST_00004  ./test/TEST_00004.jpg            4"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./test_with_predictions2.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3710e3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. test.csv 읽기\n",
    "df = pd.read_csv(\"./test_with_predictions2.csv\")\n",
    "\n",
    "class_names = {\n",
    "    0: 'Andesite',\n",
    "    1: 'Basalt',\n",
    "    2: 'Etc',\n",
    "    3: 'Gneiss',\n",
    "    4: 'Granite',\n",
    "    5: 'Mud_Sandstone',\n",
    "    6: 'Weathered_Rock'\n",
    "}\n",
    "\n",
    "# 2. rock_type 컬럼을 예측값으로 설정\n",
    "mapped_preds = [class_names[p] for p in df[\"predictions\"]]\n",
    "df[\"rock_type\"] = mapped_preds\n",
    "\n",
    "# 3. 필요 없는 img_path 컬럼 제거\n",
    "df = df[[\"ID\", \"rock_type\"]]\n",
    "\n",
    "# 4. 저장\n",
    "df.to_csv(\"test_with_predictions2.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env312_cuda124_torch260",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
